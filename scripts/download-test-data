#!/bin/bash
#
# Kevin Murphy
# keggsmurph21 at gmail dot com

set -euo pipefail

usage() {
    cat <<EOM >&2

usage: $0

    This script downloads and extracts tarballs from an AWS S3
    bucket into the ./test-data folder.  In order to run this
    script, the following environment variables must be set and
    exported:

     - AWS_ACCESS_KEY_ID
     - AWS_SECRET_ACCESS_KEY

    To set and export these variables, you can run the following
    command from the root of the project repository:

     $ source .env

    If that file does not exist on your system, please contact
    one of the project maintainers for a copy.

EOM
    exit 1
}

# This is the output from
#
#   $ ./scripts/hash-path ./test-data
#
# when all of the required files are present and in the right place.
# If we run this command and it has a different output from the value
# below, that means we are missing files and should reconstruct the
# test data from the S3 tarballs.
#
# This value should be updated every time we make updates to ./test-data.
MAGIC_HASH="b05464f112f6ea8dd7bf9b8301a2f450"

# Download each of these dataset tarballs (space-delimited)
DATASETS="ftyers qumuq"

# enforce that all environment variables are set
[ -z "${AWS_ACCESS_KEY_ID:-}" ] && usage
[ -z "${AWS_SECRET_ACCESS_KEY:-}" ] && usage

# go to the repository root
cd "$(dirname "$0")/.."

# see if we need to download anything
if [ -d ./test-data ]; then
    current_hash=$(./scripts/hash-path ./test-data)
    if [[ $current_hash == $MAGIC_HASH ]]; then
        echo "hash matches expected value, exiting!" >&2
        exit 0
    else
        echo "hash doesn't match expected value, pulling latest data ..." >&2
        rm -rf ./test-data
    fi
fi

mkdir ./test-data

# download the files using python AWS SDK
cat <<DOWNLOAD | python3

import boto3
import sys

BUCKET = "swatphonlab"
PREFIX = "ultratrace-test-data"

s3 = boto3.client("s3")

for dataset in "$DATASETS".split():
    tarball = f"{PREFIX}/{dataset}.tar.gz"
    print(
        f"downloading s3://{BUCKET}/{tarball} ...",
        file=sys.stderr,
    )
    s3.download_file(
        Bucket=BUCKET,
        Key=tarball,
        Filename=f"./test-data/{dataset}.tar.gz",
    )

DOWNLOAD

cd ./test-data

# extract tarballs
for dataset in $DATASETS; do
    echo "extracting ./$dataset.tar.gz ..." >&2
    tar xf "./$dataset.tar.gz"
    rm "./$dataset.tar.gz"
done

cd ..

echo "done!" >&2

# FIXME: Build up some more trivial test directories
